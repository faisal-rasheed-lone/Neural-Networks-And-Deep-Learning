{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7838ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e1ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Project101/final_dataset/train'\n",
    "val_dir = 'Project101/final_dataset/validation'\n",
    "test_dir = 'Project101/final_dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6b4947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 images belonging to 101 classes.\n",
      "Found 10100 images belonging to 101 classes.\n",
      "Found 15150 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load and preprocess the Food 101 dataset\n",
    "# Make sure to have the dataset in the correct structure (train/val subdirectories for each class)\n",
    "# You might need to resize images to (299, 299) as InceptionV3 requires this size\n",
    "\n",
    "# Use the built-in preprocessing function for InceptionV3\n",
    "\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "train_datagen = ImageDataGenerator(                            \n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2\n",
    "  )\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a90f96cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained DenseNet121 model\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new classification layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(101, activation='softmax')(x)\n",
    "\n",
    "# Define the new model\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e351cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 50176)        0           ['relu[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           3211328     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 101)          6565        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,255,397\n",
      "Trainable params: 3,217,893\n",
      "Non-trainable params: 7,037,504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "588fa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint_callback = ModelCheckpoint('dense_transfer_learning_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='min', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39963116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112d54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('dense_transfer_learning_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef7d9af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7912 - accuracy: 0.2736\n",
      "Epoch 1: val_loss improved from inf to 2.77462, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 823s 173ms/step - loss: 2.7912 - accuracy: 0.2736 - val_loss: 2.7746 - val_accuracy: 0.2759 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7884 - accuracy: 0.2735\n",
      "Epoch 2: val_loss improved from 2.77462 to 2.72756, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 701s 148ms/step - loss: 2.7884 - accuracy: 0.2735 - val_loss: 2.7276 - val_accuracy: 0.2852 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7898 - accuracy: 0.2749\n",
      "Epoch 3: val_loss did not improve from 2.72756\n",
      "4735/4735 [==============================] - 703s 148ms/step - loss: 2.7898 - accuracy: 0.2749 - val_loss: 2.7308 - val_accuracy: 0.2833 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7873 - accuracy: 0.2726\n",
      "Epoch 4: val_loss improved from 2.72756 to 2.72604, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 705s 149ms/step - loss: 2.7873 - accuracy: 0.2726 - val_loss: 2.7260 - val_accuracy: 0.2803 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7860 - accuracy: 0.2738\n",
      "Epoch 5: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 700s 148ms/step - loss: 2.7860 - accuracy: 0.2738 - val_loss: 2.7342 - val_accuracy: 0.2813 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7906 - accuracy: 0.2735\n",
      "Epoch 6: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 706s 149ms/step - loss: 2.7906 - accuracy: 0.2735 - val_loss: 2.7463 - val_accuracy: 0.2712 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7895 - accuracy: 0.2745\n",
      "Epoch 7: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 718s 152ms/step - loss: 2.7895 - accuracy: 0.2745 - val_loss: 2.7530 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7849 - accuracy: 0.2733\n",
      "Epoch 8: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7849 - accuracy: 0.2733 - val_loss: 2.7346 - val_accuracy: 0.2856 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7855 - accuracy: 0.2756\n",
      "Epoch 9: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 702s 148ms/step - loss: 2.7855 - accuracy: 0.2756 - val_loss: 2.7350 - val_accuracy: 0.2806 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7874 - accuracy: 0.2734\n",
      "Epoch 10: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 703s 149ms/step - loss: 2.7874 - accuracy: 0.2734 - val_loss: 2.7318 - val_accuracy: 0.2842 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7844 - accuracy: 0.2743\n",
      "Epoch 11: val_loss did not improve from 2.72604\n",
      "4735/4735 [==============================] - 704s 149ms/step - loss: 2.7844 - accuracy: 0.2743 - val_loss: 2.7465 - val_accuracy: 0.2815 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7826 - accuracy: 0.2756\n",
      "Epoch 12: val_loss improved from 2.72604 to 2.72296, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 700s 148ms/step - loss: 2.7826 - accuracy: 0.2756 - val_loss: 2.7230 - val_accuracy: 0.2880 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7840 - accuracy: 0.2752\n",
      "Epoch 13: val_loss did not improve from 2.72296\n",
      "4735/4735 [==============================] - 701s 148ms/step - loss: 2.7840 - accuracy: 0.2752 - val_loss: 2.7348 - val_accuracy: 0.2834 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7804 - accuracy: 0.2766\n",
      "Epoch 14: val_loss improved from 2.72296 to 2.71927, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 701s 148ms/step - loss: 2.7804 - accuracy: 0.2766 - val_loss: 2.7193 - val_accuracy: 0.2863 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7808 - accuracy: 0.2741\n",
      "Epoch 15: val_loss did not improve from 2.71927\n",
      "4735/4735 [==============================] - 702s 148ms/step - loss: 2.7808 - accuracy: 0.2741 - val_loss: 2.7319 - val_accuracy: 0.2809 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7828 - accuracy: 0.2760\n",
      "Epoch 16: val_loss did not improve from 2.71927\n",
      "4735/4735 [==============================] - 698s 147ms/step - loss: 2.7828 - accuracy: 0.2760 - val_loss: 2.7209 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7799 - accuracy: 0.2761\n",
      "Epoch 17: val_loss did not improve from 2.71927\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7799 - accuracy: 0.2761 - val_loss: 2.7256 - val_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7785 - accuracy: 0.2747\n",
      "Epoch 18: val_loss did not improve from 2.71927\n",
      "4735/4735 [==============================] - 701s 148ms/step - loss: 2.7785 - accuracy: 0.2747 - val_loss: 2.7288 - val_accuracy: 0.2848 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7814 - accuracy: 0.2745\n",
      "Epoch 19: val_loss improved from 2.71927 to 2.71881, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7814 - accuracy: 0.2745 - val_loss: 2.7188 - val_accuracy: 0.2879 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7773 - accuracy: 0.2764\n",
      "Epoch 20: val_loss did not improve from 2.71881\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7773 - accuracy: 0.2764 - val_loss: 2.7429 - val_accuracy: 0.2802 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7806 - accuracy: 0.2766\n",
      "Epoch 21: val_loss improved from 2.71881 to 2.71512, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7806 - accuracy: 0.2766 - val_loss: 2.7151 - val_accuracy: 0.2882 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7772 - accuracy: 0.2766\n",
      "Epoch 22: val_loss improved from 2.71512 to 2.71124, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7772 - accuracy: 0.2766 - val_loss: 2.7112 - val_accuracy: 0.2839 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7782 - accuracy: 0.2744\n",
      "Epoch 23: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.7782 - accuracy: 0.2744 - val_loss: 2.7472 - val_accuracy: 0.2807 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7778 - accuracy: 0.2751\n",
      "Epoch 24: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7778 - accuracy: 0.2751 - val_loss: 2.7240 - val_accuracy: 0.2840 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7740 - accuracy: 0.2774\n",
      "Epoch 25: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 687s 145ms/step - loss: 2.7740 - accuracy: 0.2774 - val_loss: 2.7242 - val_accuracy: 0.2853 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7774 - accuracy: 0.2774\n",
      "Epoch 26: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7774 - accuracy: 0.2774 - val_loss: 2.7267 - val_accuracy: 0.2841 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7733 - accuracy: 0.2765\n",
      "Epoch 27: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7733 - accuracy: 0.2765 - val_loss: 2.7434 - val_accuracy: 0.2810 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7717 - accuracy: 0.2777\n",
      "Epoch 28: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7717 - accuracy: 0.2777 - val_loss: 2.7278 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7744 - accuracy: 0.2770\n",
      "Epoch 29: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.7744 - accuracy: 0.2770 - val_loss: 2.7183 - val_accuracy: 0.2805 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7714 - accuracy: 0.2770\n",
      "Epoch 30: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 689s 145ms/step - loss: 2.7714 - accuracy: 0.2770 - val_loss: 2.7286 - val_accuracy: 0.2798 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7740 - accuracy: 0.2760\n",
      "Epoch 31: val_loss did not improve from 2.71124\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7740 - accuracy: 0.2760 - val_loss: 2.7191 - val_accuracy: 0.2830 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7652 - accuracy: 0.2792\n",
      "Epoch 32: val_loss did not improve from 2.71124\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7652 - accuracy: 0.2792 - val_loss: 2.7293 - val_accuracy: 0.2806 - lr: 1.0000e-04\n",
      "Epoch 32: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "        train_generator,\n",
    "        epochs=300,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a716ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7320 - accuracy: 0.2876\n",
      "Epoch 1: val_loss improved from 2.71124 to 2.69438, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7320 - accuracy: 0.2876 - val_loss: 2.6944 - val_accuracy: 0.2914 - lr: 1.0000e-05\n",
      "Epoch 2/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7292 - accuracy: 0.2893\n",
      "Epoch 2: val_loss improved from 2.69438 to 2.69434, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7292 - accuracy: 0.2893 - val_loss: 2.6943 - val_accuracy: 0.2924 - lr: 1.0000e-05\n",
      "Epoch 3/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7271 - accuracy: 0.2888\n",
      "Epoch 3: val_loss did not improve from 2.69434\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.7271 - accuracy: 0.2888 - val_loss: 2.6953 - val_accuracy: 0.2923 - lr: 1.0000e-05\n",
      "Epoch 4/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7262 - accuracy: 0.2897\n",
      "Epoch 4: val_loss improved from 2.69434 to 2.68940, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 689s 145ms/step - loss: 2.7262 - accuracy: 0.2897 - val_loss: 2.6894 - val_accuracy: 0.2929 - lr: 1.0000e-05\n",
      "Epoch 5/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7270 - accuracy: 0.2887\n",
      "Epoch 5: val_loss did not improve from 2.68940\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.7270 - accuracy: 0.2887 - val_loss: 2.6919 - val_accuracy: 0.2919 - lr: 1.0000e-05\n",
      "Epoch 6/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7255 - accuracy: 0.2880\n",
      "Epoch 6: val_loss did not improve from 2.68940\n",
      "4735/4735 [==============================] - 689s 145ms/step - loss: 2.7255 - accuracy: 0.2880 - val_loss: 2.6900 - val_accuracy: 0.2917 - lr: 1.0000e-05\n",
      "Epoch 7/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7231 - accuracy: 0.2910\n",
      "Epoch 7: val_loss improved from 2.68940 to 2.68705, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 689s 145ms/step - loss: 2.7231 - accuracy: 0.2910 - val_loss: 2.6871 - val_accuracy: 0.2924 - lr: 1.0000e-05\n",
      "Epoch 8/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7224 - accuracy: 0.2895\n",
      "Epoch 8: val_loss did not improve from 2.68705\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7224 - accuracy: 0.2895 - val_loss: 2.6874 - val_accuracy: 0.2917 - lr: 1.0000e-05\n",
      "Epoch 9/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7251 - accuracy: 0.2895\n",
      "Epoch 9: val_loss did not improve from 2.68705\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.7251 - accuracy: 0.2895 - val_loss: 2.6875 - val_accuracy: 0.2924 - lr: 1.0000e-05\n",
      "Epoch 10/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7220 - accuracy: 0.2888\n",
      "Epoch 10: val_loss improved from 2.68705 to 2.68687, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7220 - accuracy: 0.2888 - val_loss: 2.6869 - val_accuracy: 0.2942 - lr: 1.0000e-05\n",
      "Epoch 11/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7243 - accuracy: 0.2900\n",
      "Epoch 11: val_loss improved from 2.68687 to 2.68607, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7243 - accuracy: 0.2900 - val_loss: 2.6861 - val_accuracy: 0.2941 - lr: 1.0000e-05\n",
      "Epoch 12/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7210 - accuracy: 0.2884\n",
      "Epoch 12: val_loss improved from 2.68607 to 2.68481, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7210 - accuracy: 0.2884 - val_loss: 2.6848 - val_accuracy: 0.2923 - lr: 1.0000e-05\n",
      "Epoch 13/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7168 - accuracy: 0.2910\n",
      "Epoch 13: val_loss did not improve from 2.68481\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7168 - accuracy: 0.2910 - val_loss: 2.6884 - val_accuracy: 0.2925 - lr: 1.0000e-05\n",
      "Epoch 14/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7194 - accuracy: 0.2904\n",
      "Epoch 14: val_loss improved from 2.68481 to 2.68455, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7194 - accuracy: 0.2904 - val_loss: 2.6845 - val_accuracy: 0.2930 - lr: 1.0000e-05\n",
      "Epoch 15/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7231 - accuracy: 0.2910\n",
      "Epoch 15: val_loss improved from 2.68455 to 2.68341, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7231 - accuracy: 0.2910 - val_loss: 2.6834 - val_accuracy: 0.2922 - lr: 1.0000e-05\n",
      "Epoch 16/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7191 - accuracy: 0.2909\n",
      "Epoch 16: val_loss improved from 2.68341 to 2.68283, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7191 - accuracy: 0.2909 - val_loss: 2.6828 - val_accuracy: 0.2929 - lr: 1.0000e-05\n",
      "Epoch 17/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7196 - accuracy: 0.2928\n",
      "Epoch 17: val_loss did not improve from 2.68283\n",
      "4735/4735 [==============================] - 709s 150ms/step - loss: 2.7196 - accuracy: 0.2928 - val_loss: 2.6838 - val_accuracy: 0.2935 - lr: 1.0000e-05\n",
      "Epoch 18/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7180 - accuracy: 0.2915\n",
      "Epoch 18: val_loss did not improve from 2.68283\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.7180 - accuracy: 0.2915 - val_loss: 2.6841 - val_accuracy: 0.2950 - lr: 1.0000e-05\n",
      "Epoch 19/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7209 - accuracy: 0.2921\n",
      "Epoch 19: val_loss did not improve from 2.68283\n",
      "4735/4735 [==============================] - 702s 148ms/step - loss: 2.7209 - accuracy: 0.2921 - val_loss: 2.6863 - val_accuracy: 0.2917 - lr: 1.0000e-05\n",
      "Epoch 20/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7160 - accuracy: 0.2913\n",
      "Epoch 20: val_loss improved from 2.68283 to 2.68263, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 697s 147ms/step - loss: 2.7160 - accuracy: 0.2913 - val_loss: 2.6826 - val_accuracy: 0.2918 - lr: 1.0000e-05\n",
      "Epoch 21/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7136 - accuracy: 0.2905\n",
      "Epoch 21: val_loss did not improve from 2.68263\n",
      "4735/4735 [==============================] - 689s 145ms/step - loss: 2.7136 - accuracy: 0.2905 - val_loss: 2.6848 - val_accuracy: 0.2948 - lr: 1.0000e-05\n",
      "Epoch 22/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7181 - accuracy: 0.2922\n",
      "Epoch 22: val_loss did not improve from 2.68263\n",
      "4735/4735 [==============================] - 689s 145ms/step - loss: 2.7181 - accuracy: 0.2922 - val_loss: 2.6839 - val_accuracy: 0.2920 - lr: 1.0000e-05\n",
      "Epoch 23/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7171 - accuracy: 0.2901\n",
      "Epoch 23: val_loss did not improve from 2.68263\n",
      "4735/4735 [==============================] - 699s 148ms/step - loss: 2.7171 - accuracy: 0.2901 - val_loss: 2.6828 - val_accuracy: 0.2944 - lr: 1.0000e-05\n",
      "Epoch 24/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7165 - accuracy: 0.2936\n",
      "Epoch 24: val_loss did not improve from 2.68263\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7165 - accuracy: 0.2936 - val_loss: 2.6836 - val_accuracy: 0.2920 - lr: 1.0000e-05\n",
      "Epoch 25/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7188 - accuracy: 0.2910\n",
      "Epoch 25: val_loss improved from 2.68263 to 2.67872, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 686s 145ms/step - loss: 2.7188 - accuracy: 0.2910 - val_loss: 2.6787 - val_accuracy: 0.2950 - lr: 1.0000e-05\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7176 - accuracy: 0.2925\n",
      "Epoch 26: val_loss did not improve from 2.67872\n",
      "4735/4735 [==============================] - 697s 147ms/step - loss: 2.7176 - accuracy: 0.2925 - val_loss: 2.6809 - val_accuracy: 0.2935 - lr: 1.0000e-05\n",
      "Epoch 27/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7209 - accuracy: 0.2920\n",
      "Epoch 27: val_loss did not improve from 2.67872\n",
      "4735/4735 [==============================] - 697s 147ms/step - loss: 2.7209 - accuracy: 0.2920 - val_loss: 2.6797 - val_accuracy: 0.2969 - lr: 1.0000e-05\n",
      "Epoch 28/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7212 - accuracy: 0.2906\n",
      "Epoch 28: val_loss did not improve from 2.67872\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7212 - accuracy: 0.2906 - val_loss: 2.6847 - val_accuracy: 0.2924 - lr: 1.0000e-05\n",
      "Epoch 29/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7135 - accuracy: 0.2916\n",
      "Epoch 29: val_loss did not improve from 2.67872\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7135 - accuracy: 0.2916 - val_loss: 2.6819 - val_accuracy: 0.2932 - lr: 1.0000e-05\n",
      "Epoch 30/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7146 - accuracy: 0.2922\n",
      "Epoch 30: val_loss did not improve from 2.67872\n",
      "4735/4735 [==============================] - 694s 146ms/step - loss: 2.7146 - accuracy: 0.2922 - val_loss: 2.6816 - val_accuracy: 0.2962 - lr: 1.0000e-05\n",
      "Epoch 31/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7154 - accuracy: 0.2908\n",
      "Epoch 31: val_loss improved from 2.67872 to 2.67852, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7154 - accuracy: 0.2908 - val_loss: 2.6785 - val_accuracy: 0.2952 - lr: 1.0000e-05\n",
      "Epoch 32/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7155 - accuracy: 0.2921\n",
      "Epoch 32: val_loss did not improve from 2.67852\n",
      "4735/4735 [==============================] - 700s 148ms/step - loss: 2.7155 - accuracy: 0.2921 - val_loss: 2.6802 - val_accuracy: 0.2931 - lr: 1.0000e-05\n",
      "Epoch 33/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7178 - accuracy: 0.2918\n",
      "Epoch 33: val_loss did not improve from 2.67852\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7178 - accuracy: 0.2918 - val_loss: 2.6835 - val_accuracy: 0.2946 - lr: 1.0000e-05\n",
      "Epoch 34/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7178 - accuracy: 0.2911\n",
      "Epoch 34: val_loss did not improve from 2.67852\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7178 - accuracy: 0.2911 - val_loss: 2.6820 - val_accuracy: 0.2946 - lr: 1.0000e-05\n",
      "Epoch 35/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7138 - accuracy: 0.2902\n",
      "Epoch 35: val_loss did not improve from 2.67852\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7138 - accuracy: 0.2902 - val_loss: 2.6813 - val_accuracy: 0.2937 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7208 - accuracy: 0.2916\n",
      "Epoch 36: val_loss did not improve from 2.67852\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7208 - accuracy: 0.2916 - val_loss: 2.6842 - val_accuracy: 0.2934 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7190 - accuracy: 0.2917\n",
      "Epoch 37: val_loss did not improve from 2.67852\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7190 - accuracy: 0.2917 - val_loss: 2.6835 - val_accuracy: 0.2910 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7146 - accuracy: 0.2925\n",
      "Epoch 38: val_loss improved from 2.67852 to 2.67681, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 698s 147ms/step - loss: 2.7146 - accuracy: 0.2925 - val_loss: 2.6768 - val_accuracy: 0.2929 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7153 - accuracy: 0.2924\n",
      "Epoch 39: val_loss did not improve from 2.67681\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7153 - accuracy: 0.2924 - val_loss: 2.6802 - val_accuracy: 0.2967 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7156 - accuracy: 0.2915\n",
      "Epoch 40: val_loss did not improve from 2.67681\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7156 - accuracy: 0.2915 - val_loss: 2.6795 - val_accuracy: 0.2969 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7109 - accuracy: 0.2919\n",
      "Epoch 41: val_loss did not improve from 2.67681\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.7109 - accuracy: 0.2919 - val_loss: 2.6786 - val_accuracy: 0.2917 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7170 - accuracy: 0.2912\n",
      "Epoch 42: val_loss improved from 2.67681 to 2.67595, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 697s 147ms/step - loss: 2.7170 - accuracy: 0.2912 - val_loss: 2.6760 - val_accuracy: 0.2942 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7159 - accuracy: 0.2915\n",
      "Epoch 43: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.7159 - accuracy: 0.2915 - val_loss: 2.6782 - val_accuracy: 0.2943 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7154 - accuracy: 0.2949\n",
      "Epoch 44: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7154 - accuracy: 0.2949 - val_loss: 2.6854 - val_accuracy: 0.2916 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7157 - accuracy: 0.2887\n",
      "Epoch 45: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7157 - accuracy: 0.2887 - val_loss: 2.6781 - val_accuracy: 0.2950 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7170 - accuracy: 0.2921\n",
      "Epoch 46: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7170 - accuracy: 0.2921 - val_loss: 2.6811 - val_accuracy: 0.2948 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7162 - accuracy: 0.2925\n",
      "Epoch 47: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 689s 146ms/step - loss: 2.7162 - accuracy: 0.2925 - val_loss: 2.6822 - val_accuracy: 0.2949 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7132 - accuracy: 0.2918\n",
      "Epoch 48: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7132 - accuracy: 0.2918 - val_loss: 2.6793 - val_accuracy: 0.2957 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7159 - accuracy: 0.2922\n",
      "Epoch 49: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.7159 - accuracy: 0.2922 - val_loss: 2.6785 - val_accuracy: 0.2928 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7136 - accuracy: 0.2923\n",
      "Epoch 50: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 688s 145ms/step - loss: 2.7136 - accuracy: 0.2923 - val_loss: 2.6791 - val_accuracy: 0.2955 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7116 - accuracy: 0.2915\n",
      "Epoch 51: val_loss did not improve from 2.67595\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.7116 - accuracy: 0.2915 - val_loss: 2.6785 - val_accuracy: 0.2947 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7133 - accuracy: 0.2918\n",
      "Epoch 52: val_loss improved from 2.67595 to 2.67515, saving model to dense_transfer_learning_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4735/4735 [==============================] - 703s 149ms/step - loss: 2.7133 - accuracy: 0.2918 - val_loss: 2.6751 - val_accuracy: 0.2959 - lr: 1.0000e-05\n",
      "Epoch 53/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7128 - accuracy: 0.2916\n",
      "Epoch 53: val_loss did not improve from 2.67515\n",
      "4735/4735 [==============================] - 699s 148ms/step - loss: 2.7128 - accuracy: 0.2916 - val_loss: 2.6777 - val_accuracy: 0.2939 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7108 - accuracy: 0.2942\n",
      "Epoch 54: val_loss did not improve from 2.67515\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7108 - accuracy: 0.2942 - val_loss: 2.6768 - val_accuracy: 0.2966 - lr: 1.0000e-05\n",
      "Epoch 55/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7110 - accuracy: 0.2929\n",
      "Epoch 55: val_loss did not improve from 2.67515\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.7110 - accuracy: 0.2929 - val_loss: 2.6770 - val_accuracy: 0.2959 - lr: 1.0000e-05\n",
      "Epoch 56/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7134 - accuracy: 0.2940\n",
      "Epoch 56: val_loss did not improve from 2.67515\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.7134 - accuracy: 0.2940 - val_loss: 2.6802 - val_accuracy: 0.2940 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.7114 - accuracy: 0.2935\n",
      "Epoch 57: val_loss improved from 2.67515 to 2.67074, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 690s 146ms/step - loss: 2.7114 - accuracy: 0.2935 - val_loss: 2.6707 - val_accuracy: 0.3008 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6982 - accuracy: 0.2968\n",
      "Epoch 58: val_loss improved from 2.67074 to 2.65918, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.6982 - accuracy: 0.2968 - val_loss: 2.6592 - val_accuracy: 0.3081 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6915 - accuracy: 0.3042\n",
      "Epoch 59: val_loss improved from 2.65918 to 2.64792, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.6915 - accuracy: 0.3042 - val_loss: 2.6479 - val_accuracy: 0.3103 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6807 - accuracy: 0.3044\n",
      "Epoch 60: val_loss improved from 2.64792 to 2.64344, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 705s 149ms/step - loss: 2.6807 - accuracy: 0.3044 - val_loss: 2.6434 - val_accuracy: 0.3130 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6741 - accuracy: 0.3080\n",
      "Epoch 61: val_loss improved from 2.64344 to 2.63636, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 701s 148ms/step - loss: 2.6741 - accuracy: 0.3080 - val_loss: 2.6364 - val_accuracy: 0.3160 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6693 - accuracy: 0.3095\n",
      "Epoch 62: val_loss improved from 2.63636 to 2.63467, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 705s 149ms/step - loss: 2.6693 - accuracy: 0.3095 - val_loss: 2.6347 - val_accuracy: 0.3176 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6684 - accuracy: 0.3106\n",
      "Epoch 63: val_loss improved from 2.63467 to 2.63362, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 701s 148ms/step - loss: 2.6684 - accuracy: 0.3106 - val_loss: 2.6336 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6631 - accuracy: 0.3097\n",
      "Epoch 64: val_loss improved from 2.63362 to 2.62261, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 698s 147ms/step - loss: 2.6631 - accuracy: 0.3097 - val_loss: 2.6226 - val_accuracy: 0.3156 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6584 - accuracy: 0.3107\n",
      "Epoch 65: val_loss improved from 2.62261 to 2.62081, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.6584 - accuracy: 0.3107 - val_loss: 2.6208 - val_accuracy: 0.3190 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6565 - accuracy: 0.3120\n",
      "Epoch 66: val_loss improved from 2.62081 to 2.61508, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 700s 148ms/step - loss: 2.6565 - accuracy: 0.3120 - val_loss: 2.6151 - val_accuracy: 0.3217 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6548 - accuracy: 0.3140\n",
      "Epoch 67: val_loss did not improve from 2.61508\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.6548 - accuracy: 0.3140 - val_loss: 2.6162 - val_accuracy: 0.3211 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6464 - accuracy: 0.3148\n",
      "Epoch 68: val_loss improved from 2.61508 to 2.60891, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 699s 148ms/step - loss: 2.6464 - accuracy: 0.3148 - val_loss: 2.6089 - val_accuracy: 0.3221 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6441 - accuracy: 0.3158\n",
      "Epoch 69: val_loss did not improve from 2.60891\n",
      "4735/4735 [==============================] - 702s 148ms/step - loss: 2.6441 - accuracy: 0.3158 - val_loss: 2.6099 - val_accuracy: 0.3205 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6456 - accuracy: 0.3164\n",
      "Epoch 70: val_loss improved from 2.60891 to 2.60331, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.6456 - accuracy: 0.3164 - val_loss: 2.6033 - val_accuracy: 0.3215 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6399 - accuracy: 0.3163\n",
      "Epoch 71: val_loss did not improve from 2.60331\n",
      "4735/4735 [==============================] - 699s 148ms/step - loss: 2.6399 - accuracy: 0.3163 - val_loss: 2.6075 - val_accuracy: 0.3206 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6384 - accuracy: 0.3172\n",
      "Epoch 72: val_loss improved from 2.60331 to 2.60217, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.6384 - accuracy: 0.3172 - val_loss: 2.6022 - val_accuracy: 0.3229 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6394 - accuracy: 0.3177\n",
      "Epoch 73: val_loss did not improve from 2.60217\n",
      "4735/4735 [==============================] - 699s 148ms/step - loss: 2.6394 - accuracy: 0.3177 - val_loss: 2.6051 - val_accuracy: 0.3241 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6334 - accuracy: 0.3187\n",
      "Epoch 74: val_loss improved from 2.60217 to 2.60054, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 703s 148ms/step - loss: 2.6334 - accuracy: 0.3187 - val_loss: 2.6005 - val_accuracy: 0.3221 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6328 - accuracy: 0.3198\n",
      "Epoch 75: val_loss improved from 2.60054 to 2.59429, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 699s 148ms/step - loss: 2.6328 - accuracy: 0.3198 - val_loss: 2.5943 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
      "Epoch 76/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6323 - accuracy: 0.3207\n",
      "Epoch 76: val_loss improved from 2.59429 to 2.59229, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.6323 - accuracy: 0.3207 - val_loss: 2.5923 - val_accuracy: 0.3262 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6262 - accuracy: 0.3201\n",
      "Epoch 77: val_loss improved from 2.59229 to 2.59099, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 704s 149ms/step - loss: 2.6262 - accuracy: 0.3201 - val_loss: 2.5910 - val_accuracy: 0.3246 - lr: 1.0000e-05\n",
      "Epoch 78/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6282 - accuracy: 0.3199\n",
      "Epoch 78: val_loss did not improve from 2.59099\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.6282 - accuracy: 0.3199 - val_loss: 2.5925 - val_accuracy: 0.3250 - lr: 1.0000e-05\n",
      "Epoch 79/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6254 - accuracy: 0.3201\n",
      "Epoch 79: val_loss improved from 2.59099 to 2.58817, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.6254 - accuracy: 0.3201 - val_loss: 2.5882 - val_accuracy: 0.3255 - lr: 1.0000e-05\n",
      "Epoch 80/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6230 - accuracy: 0.3204\n",
      "Epoch 80: val_loss improved from 2.58817 to 2.58302, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.6230 - accuracy: 0.3204 - val_loss: 2.5830 - val_accuracy: 0.3278 - lr: 1.0000e-05\n",
      "Epoch 81/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6212 - accuracy: 0.3212\n",
      "Epoch 81: val_loss did not improve from 2.58302\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.6212 - accuracy: 0.3212 - val_loss: 2.5833 - val_accuracy: 0.3254 - lr: 1.0000e-05\n",
      "Epoch 82/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6203 - accuracy: 0.3217\n",
      "Epoch 82: val_loss did not improve from 2.58302\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.6203 - accuracy: 0.3217 - val_loss: 2.5891 - val_accuracy: 0.3258 - lr: 1.0000e-05\n",
      "Epoch 83/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6162 - accuracy: 0.3222\n",
      "Epoch 83: val_loss did not improve from 2.58302\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.6162 - accuracy: 0.3222 - val_loss: 2.5901 - val_accuracy: 0.3259 - lr: 1.0000e-05\n",
      "Epoch 84/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6160 - accuracy: 0.3221\n",
      "Epoch 84: val_loss did not improve from 2.58302\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.6160 - accuracy: 0.3221 - val_loss: 2.5851 - val_accuracy: 0.3253 - lr: 1.0000e-05\n",
      "Epoch 85/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6091 - accuracy: 0.3221\n",
      "Epoch 85: val_loss improved from 2.58302 to 2.57729, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.6091 - accuracy: 0.3221 - val_loss: 2.5773 - val_accuracy: 0.3299 - lr: 1.0000e-05\n",
      "Epoch 86/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6111 - accuracy: 0.3238\n",
      "Epoch 86: val_loss improved from 2.57729 to 2.57697, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.6111 - accuracy: 0.3238 - val_loss: 2.5770 - val_accuracy: 0.3293 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6094 - accuracy: 0.3222\n",
      "Epoch 87: val_loss improved from 2.57697 to 2.57548, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.6094 - accuracy: 0.3222 - val_loss: 2.5755 - val_accuracy: 0.3278 - lr: 1.0000e-05\n",
      "Epoch 88/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6129 - accuracy: 0.3221\n",
      "Epoch 88: val_loss improved from 2.57548 to 2.57134, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.6129 - accuracy: 0.3221 - val_loss: 2.5713 - val_accuracy: 0.3281 - lr: 1.0000e-05\n",
      "Epoch 89/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6021 - accuracy: 0.3234\n",
      "Epoch 89: val_loss did not improve from 2.57134\n",
      "4735/4735 [==============================] - 688s 145ms/step - loss: 2.6021 - accuracy: 0.3234 - val_loss: 2.5816 - val_accuracy: 0.3293 - lr: 1.0000e-05\n",
      "Epoch 90/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6064 - accuracy: 0.3254\n",
      "Epoch 90: val_loss did not improve from 2.57134\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.6064 - accuracy: 0.3254 - val_loss: 2.5729 - val_accuracy: 0.3305 - lr: 1.0000e-05\n",
      "Epoch 91/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6055 - accuracy: 0.3228\n",
      "Epoch 91: val_loss did not improve from 2.57134\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.6055 - accuracy: 0.3228 - val_loss: 2.5755 - val_accuracy: 0.3262 - lr: 1.0000e-05\n",
      "Epoch 92/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.6027 - accuracy: 0.3250\n",
      "Epoch 92: val_loss improved from 2.57134 to 2.57070, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.6027 - accuracy: 0.3250 - val_loss: 2.5707 - val_accuracy: 0.3307 - lr: 1.0000e-05\n",
      "Epoch 93/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5968 - accuracy: 0.3255\n",
      "Epoch 93: val_loss did not improve from 2.57070\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.5968 - accuracy: 0.3255 - val_loss: 2.5711 - val_accuracy: 0.3277 - lr: 1.0000e-05\n",
      "Epoch 94/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5993 - accuracy: 0.3253\n",
      "Epoch 94: val_loss improved from 2.57070 to 2.56008, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.5993 - accuracy: 0.3253 - val_loss: 2.5601 - val_accuracy: 0.3293 - lr: 1.0000e-05\n",
      "Epoch 95/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5957 - accuracy: 0.3261\n",
      "Epoch 95: val_loss did not improve from 2.56008\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.5957 - accuracy: 0.3261 - val_loss: 2.5646 - val_accuracy: 0.3305 - lr: 1.0000e-05\n",
      "Epoch 96/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5972 - accuracy: 0.3261\n",
      "Epoch 96: val_loss did not improve from 2.56008\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.5972 - accuracy: 0.3261 - val_loss: 2.5700 - val_accuracy: 0.3300 - lr: 1.0000e-05\n",
      "Epoch 97/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5942 - accuracy: 0.3262\n",
      "Epoch 97: val_loss did not improve from 2.56008\n",
      "4735/4735 [==============================] - 695s 147ms/step - loss: 2.5942 - accuracy: 0.3262 - val_loss: 2.5685 - val_accuracy: 0.3289 - lr: 1.0000e-05\n",
      "Epoch 98/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5898 - accuracy: 0.3259\n",
      "Epoch 98: val_loss did not improve from 2.56008\n",
      "4735/4735 [==============================] - 694s 146ms/step - loss: 2.5898 - accuracy: 0.3259 - val_loss: 2.5616 - val_accuracy: 0.3312 - lr: 1.0000e-05\n",
      "Epoch 99/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5893 - accuracy: 0.3276\n",
      "Epoch 99: val_loss improved from 2.56008 to 2.55789, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.5893 - accuracy: 0.3276 - val_loss: 2.5579 - val_accuracy: 0.3319 - lr: 1.0000e-05\n",
      "Epoch 100/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5872 - accuracy: 0.3298\n",
      "Epoch 100: val_loss did not improve from 2.55789\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.5872 - accuracy: 0.3298 - val_loss: 2.5619 - val_accuracy: 0.3316 - lr: 1.0000e-05\n",
      "Epoch 101/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5846 - accuracy: 0.3293\n",
      "Epoch 101: val_loss improved from 2.55789 to 2.55274, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.5846 - accuracy: 0.3293 - val_loss: 2.5527 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5872 - accuracy: 0.3290\n",
      "Epoch 102: val_loss did not improve from 2.55274\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.5872 - accuracy: 0.3290 - val_loss: 2.5569 - val_accuracy: 0.3311 - lr: 1.0000e-05\n",
      "Epoch 103/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5863 - accuracy: 0.3282\n",
      "Epoch 103: val_loss improved from 2.55274 to 2.55090, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 692s 146ms/step - loss: 2.5863 - accuracy: 0.3282 - val_loss: 2.5509 - val_accuracy: 0.3338 - lr: 1.0000e-05\n",
      "Epoch 104/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5863 - accuracy: 0.3275\n",
      "Epoch 104: val_loss did not improve from 2.55090\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.5863 - accuracy: 0.3275 - val_loss: 2.5551 - val_accuracy: 0.3322 - lr: 1.0000e-05\n",
      "Epoch 105/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5824 - accuracy: 0.3299\n",
      "Epoch 105: val_loss improved from 2.55090 to 2.54827, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 693s 146ms/step - loss: 2.5824 - accuracy: 0.3299 - val_loss: 2.5483 - val_accuracy: 0.3347 - lr: 1.0000e-05\n",
      "Epoch 106/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5817 - accuracy: 0.3287\n",
      "Epoch 106: val_loss did not improve from 2.54827\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.5817 - accuracy: 0.3287 - val_loss: 2.5557 - val_accuracy: 0.3318 - lr: 1.0000e-05\n",
      "Epoch 107/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5799 - accuracy: 0.3283\n",
      "Epoch 107: val_loss improved from 2.54827 to 2.54549, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 696s 147ms/step - loss: 2.5799 - accuracy: 0.3283 - val_loss: 2.5455 - val_accuracy: 0.3342 - lr: 1.0000e-05\n",
      "Epoch 108/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5788 - accuracy: 0.3284\n",
      "Epoch 108: val_loss did not improve from 2.54549\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.5788 - accuracy: 0.3284 - val_loss: 2.5516 - val_accuracy: 0.3329 - lr: 1.0000e-05\n",
      "Epoch 109/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5800 - accuracy: 0.3290\n",
      "Epoch 109: val_loss did not improve from 2.54549\n",
      "4735/4735 [==============================] - 694s 146ms/step - loss: 2.5800 - accuracy: 0.3290 - val_loss: 2.5495 - val_accuracy: 0.3337 - lr: 1.0000e-05\n",
      "Epoch 110/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5794 - accuracy: 0.3290\n",
      "Epoch 110: val_loss did not improve from 2.54549\n",
      "4735/4735 [==============================] - 694s 147ms/step - loss: 2.5794 - accuracy: 0.3290 - val_loss: 2.5478 - val_accuracy: 0.3336 - lr: 1.0000e-05\n",
      "Epoch 111/300\n",
      "4735/4735 [==============================] - ETA: 0s - loss: 2.5791 - accuracy: 0.3302\n",
      "Epoch 111: val_loss improved from 2.54549 to 2.54324, saving model to dense_transfer_learning_model.h5\n",
      "4735/4735 [==============================] - 691s 146ms/step - loss: 2.5791 - accuracy: 0.3302 - val_loss: 2.5432 - val_accuracy: 0.3350 - lr: 1.0000e-05\n",
      "Epoch 112/300\n",
      "4350/4735 [==========================>...] - ETA: 55s - loss: 2.5727 - accuracy: 0.3295"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=300,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428eb278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Model names\n",
    "models = [\"VGG16\", \"VGG19\", \"GoogleNet\", \"ResNet\", \"DenseNet\", \"MobileNet\", \n",
    "          \"EfficientNetB0\", \"EfficientNetB7\", \"Inception-Res\", \"XceptionNet\"]\n",
    "\n",
    "# Training and Validation accuracies\n",
    "training_accuracies = [44.00, 39.42, 53.10, 73.29, 61.19, 65.18, 76.73, 82.34, 58.34, 59.63]\n",
    "validation_accuracies = [42.90, 39.25, 53.58, 65.63, 60.96, 61.02, 70.77, 79.38, 58.60, 58.74]\n",
    "\n",
    "# Plotting\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bar1 = ax.bar(index, training_accuracies, bar_width, label='Training Accuracy')\n",
    "bar2 = ax.bar(index + bar_width, validation_accuracies, bar_width, label='Validation Accuracy')\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Training and Validation Accuracies of Different Models Epochs = 30')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1359d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe66919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37876d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c52354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fe41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e1350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62503938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d8294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368fc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25fea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d41a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
